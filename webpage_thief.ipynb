{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 복사할 웹페이지 URL 입력(webwave)\n",
    "- 저장할 디렉토리 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 뒤에 / 없음\n",
    "root_url = \"https://ooctvx.webwave.dev\"\n",
    "page_dir_name = \"./test_webpage\"\n",
    "os.makedirs(page_dir_name, exist_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "크롤링 및 추출 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def scroll_down(driver, scroll_pause_time=0.5):\n",
    "    # 현재 페이지 높이 가져오기\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # 현재 스크롤 위치에서 일정 부분 내리기\n",
    "        driver.execute_script(\"window.scrollBy(0, 1500);\")\n",
    "        time.sleep(scroll_pause_time)\n",
    "\n",
    "        # 새로운 페이지 높이 계산\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        # 페이지 높이가 변하지 않거나, 스크롤바가 아래까지 내려갔으면 스크롤 다운 종료\n",
    "        if new_height == last_height and driver.execute_script(\"return window.innerHeight + window.pageYOffset >= document.body.offsetHeight\"):\n",
    "            break\n",
    "\n",
    "        # 페이지 높이 업데이트\n",
    "        last_height = new_height\n",
    "\n",
    "def crawl_website(url, wait_time=10, scroll_pause_time=0.5):\n",
    "    # Chrome 드라이버 초기화\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    # 페이지 로딩 대기\n",
    "    wait = WebDriverWait(driver, wait_time)\n",
    "    wait.until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "\n",
    "    # 페이지 맨 아래까지 스크롤 다운\n",
    "    scroll_down(driver, scroll_pause_time)\n",
    "\n",
    "    # 페이지 소스 코드 가져오기\n",
    "    page_source = driver.page_source\n",
    "    driver.quit()\n",
    "    \n",
    "    return page_source\n",
    "\n",
    "def open_html_file(html_file_path):\n",
    "    with open(html_file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    return html_content\n",
    "\n",
    "def extract_file_paths_from_html_content(html_content):\n",
    "    # 이미지 파일 경로 추출\n",
    "    # image_pattern = r'[\"\\']([^\"\\']+\\.)(png|jpg|jpeg|gif|webp)[\"\\']'\n",
    "    image_pattern = r'(?:[\"\\']|:&quot;)([^{\"\\']+?\\.)(png|jpg|jpeg|gif|webp)(?:[\"\\']|&quot;)'\n",
    "    image_paths = re.findall(image_pattern, html_content)\n",
    "    # quot_pattern = r'(?<=:&quot;)([^\"\\']*?\\.)(png|jpg|jpeg|gif|webp)(?=&quot;)'\n",
    "    # quot_paths = re.findall(quot_pattern, html_content)\n",
    "    # image_paths.extend(quot_paths)\n",
    "\n",
    "    # CSS 파일 경로 추출\n",
    "    # css_pattern = r'[\"\\']([^\"\\']+\\.css)[\"\\']'\n",
    "    css_pattern = r'(?:[\"\\']|:&quot;)([^{\"\\']+?\\.css)(?:[\"\\']|&quot;)'\n",
    "    css_paths = re.findall(css_pattern, html_content)\n",
    "\n",
    "    # JavaScript 파일 경로 추출\n",
    "    # js_pattern = r'[\"\\']([^\"\\']+\\.js)[\"\\']'\n",
    "    js_pattern = r'(?:[\"\\']|:&quot;)([^{\"\\']+?\\.js)(?:[\"\\']|&quot;)'\n",
    "    js_paths = re.findall(js_pattern, html_content)\n",
    "\n",
    "    # 파일 경로 리스트 반환\n",
    "    return {\n",
    "        \"images\": [path[0] + path[1] for path in image_paths],\n",
    "        \"css\": css_paths,\n",
    "        \"js\": js_paths\n",
    "    }\n",
    "\n",
    "def extract_url_from_html_content(html_content, root_url):\n",
    "    # url_pattern = fr'(?:[\"\\']|:&quot;)({root_url}[^\"\\']+?)(?:[\"\\']|&quot;)'\n",
    "    url_pattern = fr'href=(?:[\"\\']|:&quot;)((?!http)[/#][^\"\\']+?(?<!\\.json))(?:[\"\\']|&quot;)'\n",
    "    urls = re.findall(url_pattern, html_content)\n",
    "\n",
    "    return {root_url + cur for cur in urls}\n",
    "\n",
    "def save_html(html_content, save_path):\n",
    "    try:\n",
    "        with open(save_path, mode=\"w\") as f:\n",
    "            f.write(html_content)\n",
    "    except:\n",
    "        print(f\"Error occured saving {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "def convert_to_webp(input_data, output_path=\"./webp_data.webp\", input_type=\"path\"):\n",
    "    \n",
    "    if not output_path.endswith(\".webp\"):\n",
    "        output_path = os.path.splitext(output_path)[0] + \".webp\"\n",
    "\n",
    "    if input_type == 'path':\n",
    "        # 경로일 경우\n",
    "        img = Image.open(input_data)\n",
    "        img.save(output_path, 'WEBP')\n",
    "        return output_path\n",
    "\n",
    "    elif input_type == 'binary':\n",
    "        # 바이너리일 경우\n",
    "        img = Image.open(io.BytesIO(input_data))\n",
    "        webp_bytes = io.BytesIO()\n",
    "        img.save(webp_bytes, format='WEBP')\n",
    "        webp_bytes.seek(0)\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(webp_bytes.getvalue())\n",
    "        return output_path\n",
    "\n",
    "    elif input_type == 'pil':\n",
    "        # PIL 객체일 경우\n",
    "        webp_bytes = io.BytesIO()\n",
    "        input_data.save(webp_bytes, format='WEBP')\n",
    "        webp_bytes.seek(0)\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(webp_bytes.getvalue())\n",
    "        return output_path\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid input type. Must be \"path\", \"binary\", or \"pil\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "웹페이지 구성 URL 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "crawl_url_queue = queue.Queue()\n",
    "crawl_url_queue.put(root_url)\n",
    "crawl_done_urls = set()\n",
    "\n",
    "while not crawl_url_queue.empty():\n",
    "    target_url = crawl_url_queue.get()\n",
    "    if target_url in crawl_done_urls:\n",
    "        continue\n",
    "\n",
    "    html_content = crawl_website(target_url)\n",
    "    urls = extract_url_from_html_content(html_content, root_url=root_url)\n",
    "    \n",
    "    if target_url == root_url:\n",
    "        save_html(html_content, os.path.join(page_dir_name, \"home.html\"))\n",
    "    else:\n",
    "        save_html(html_content, os.path.join(page_dir_name, \n",
    "                                             target_url.replace(root_url+\"/\",\"\")+\".html\"))\n",
    "\n",
    "    crawl_done_urls.add(target_url)\n",
    "    for url in urls:\n",
    "        if url in crawl_done_urls:\n",
    "            continue\n",
    "        else:\n",
    "            crawl_url_queue.put(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "크롤링된 구성 URL 전부 다운로드 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://ooctvx.webwave.dev/',\n",
       " 'https://ooctvx.webwave.dev//about-us',\n",
       " 'https://ooctvx.webwave.dev//contact',\n",
       " 'https://ooctvx.webwave.dev//gallery',\n",
       " 'https://ooctvx.webwave.dev//offer',\n",
       " 'https://ooctvx.webwave.dev//offer?anchorElement=wSection_11&amp;scrollMargin=50',\n",
       " 'https://ooctvx.webwave.dev//offer?anchorElement=wSection_23&amp;scrollMargin=50',\n",
       " 'https://ooctvx.webwave.dev//portfolio',\n",
       " 'https://ooctvx.webwave.dev//pricing'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawl_done_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다운로드 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def download_single(url:str, file_path):\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.134 Safari/537.36',\n",
    "        'Referer': 'https://www.google.com/',  # 이전 페이지의 주소를 여기에 추가\n",
    "        'X-Requested-With': 'XMLHttpRequest',  # AJAX 요청 여부를 나타내는 헤더\n",
    "        'Accept-Language': 'en-US,en;q=0.9',  # 사용자가 선호하는 언어 설정\n",
    "        'Connection': 'keep-alive',  # 서버와의 연결 유지 설정\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "def download_file(url:str, root_http:str):\n",
    "\n",
    "    try:\n",
    "        if not url.startswith(\"http\"):\n",
    "            file_path = \".\" + url\n",
    "            url = root_http + url\n",
    "        else:\n",
    "            http_pattern = r'^http.*\\.com'\n",
    "            match_str = re.search(http_pattern, url)[0]\n",
    "            file_path = \".\" + url.replace(match_str, \"\")\n",
    "        \n",
    "        file_name = os.path.basename(file_path)\n",
    "        dir_name = os.path.dirname(file_path)\n",
    "\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.134 Safari/537.36',\n",
    "            'Referer': 'https://www.google.com/',  # 이전 페이지의 주소를 여기에 추가\n",
    "            'X-Requested-With': 'XMLHttpRequest',  # AJAX 요청 여부를 나타내는 헤더\n",
    "            'Accept-Language': 'en-US,en;q=0.9',  # 사용자가 선호하는 언어 설정\n",
    "            'Connection': 'keep-alive',  # 서버와의 연결 유지 설정\n",
    "        }\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            return file_path[1:]\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=20)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\"Crawl Blocked\")\n",
    "        \n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        ext = os.path.splitext(url)[1].lower()\n",
    "        if ext in ['.jpg', '.jpeg', '.png', '.gif']:\n",
    "            webp_file_path = file_path.replace(ext, \".webp\")\n",
    "            if os.path.exists(webp_file_path):\n",
    "                return file_path[1:]\n",
    "            \n",
    "            convert_to_webp(response.content, output_path=webp_file_path, input_type=\"binary\")\n",
    "        \n",
    "        return file_path[1:]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e, \" occured while processing \", file_name)\n",
    "        return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "html 재구성 및 필요 파일 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./test_webpage/offer.html',\n",
       " './test_webpage/portfolio.html',\n",
       " './test_webpage/gallery.html',\n",
       " './test_webpage/pricing.html',\n",
       " './test_webpage/offer?anchorElement=wSection_23&amp;scrollMargin=50.html',\n",
       " './test_webpage/offer?anchorElement=wSection_11&amp;scrollMargin=50.html',\n",
       " './test_webpage/about-us.html',\n",
       " './test_webpage/home.html',\n",
       " './test_webpage/contact.html']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "download_single(f\"{root_url}/manifest.json\", os.path.join(page_dir_name, \"manifest.json\"))\n",
    "html_fns = glob(os.path.join(page_dir_name, \"*.html\"))\n",
    "html_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING ./test_webpage/offer.html\n",
      "Image paths: 50\n",
      "CSS paths: 7\n",
      "JavaScript paths: 22\n",
      "IMAGE FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 38657.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 20082.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 32117.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "PROCESSING ./test_webpage/portfolio.html\n",
      "Image paths: 50\n",
      "CSS paths: 7\n",
      "JavaScript paths: 22\n",
      "IMAGE FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 46510.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 20488.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 38803.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "PROCESSING ./test_webpage/gallery.html\n",
      "Image paths: 53\n",
      "CSS paths: 7\n",
      "JavaScript paths: 22\n",
      "IMAGE FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:00<00:00, 39275.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 22025.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 35098.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "PROCESSING ./test_webpage/pricing.html\n",
      "Image paths: 48\n",
      "CSS paths: 7\n",
      "JavaScript paths: 22\n",
      "IMAGE FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 33632.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 20178.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 32791.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "PROCESSING ./test_webpage/offer?anchorElement=wSection_23&amp;scrollMargin=50.html\n",
      "Image paths: 50\n",
      "CSS paths: 7\n",
      "JavaScript paths: 22\n",
      "IMAGE FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 42904.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 20734.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 32140.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "PROCESSING ./test_webpage/offer?anchorElement=wSection_11&amp;scrollMargin=50.html\n",
      "Image paths: 49\n",
      "CSS paths: 7\n",
      "JavaScript paths: 22\n",
      "IMAGE FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 44659.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 27160.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 28808.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "PROCESSING ./test_webpage/about-us.html\n",
      "Image paths: 74\n",
      "CSS paths: 7\n",
      "JavaScript paths: 22\n",
      "IMAGE FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 42728.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 26570.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 28158.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "PROCESSING ./test_webpage/home.html\n",
      "Image paths: 110\n",
      "CSS paths: 7\n",
      "JavaScript paths: 22\n",
      "IMAGE FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:00<00:00, 32929.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 22141.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 24966.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "PROCESSING ./test_webpage/contact.html\n",
      "Image paths: 38\n",
      "CSS paths: 7\n",
      "JavaScript paths: 22\n",
      "IMAGE FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 42377.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 29360.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS FILE CRAWL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 40015.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for html_fn in html_fns:\n",
    "    print(\"PROCESSING\", html_fn)\n",
    "\n",
    "    html_content = open_html_file(html_fn)\n",
    "    file_paths = extract_file_paths_from_html_content(html_content)\n",
    "\n",
    "    print(\"Image paths:\", len(file_paths[\"images\"]))\n",
    "    print(\"CSS paths:\", len(file_paths[\"css\"]))\n",
    "    print(\"JavaScript paths:\", len(file_paths[\"js\"]))\n",
    "\n",
    "    print(\"IMAGE FILE CRAWL\")\n",
    "    for cur in tqdm(file_paths[\"images\"]):\n",
    "        if cur.startswith(\"./\"): continue\n",
    "        cur_file_path = download_file(url=cur, root_http='https://yourbrand-18274.kxcdn.com')\n",
    "        html_content = html_content.replace(cur, cur_file_path)\n",
    "\n",
    "    print(\"CSS FILE CRAWL\")\n",
    "    for cur in tqdm(file_paths[\"css\"]):\n",
    "        if cur.startswith(\"./\"): continue\n",
    "        cur_file_path = download_file(url=cur, root_http='https://yourbrand-18274.kxcdn.com')\n",
    "        html_content = html_content.replace(cur, cur_file_path)\n",
    "\n",
    "    print(\"JS FILE CRAWL\")\n",
    "    for cur in tqdm(file_paths[\"js\"]):\n",
    "        if cur.startswith(\"./\"): continue\n",
    "        if \"service-worker.js\" in cur: continue\n",
    "        if \"datePickerService.js\" in cur: continue\n",
    "\n",
    "        cur_file_path = download_file(url=cur, root_http='https://yourbrand-18274.kxcdn.com')\n",
    "        html_content = html_content.replace(cur, cur_file_path)\n",
    "    \n",
    "    html_content = html_content.replace(f\"{root_url}/\", \"./\")\n",
    "    html_content = html_content.replace('data-element-type=\"button', 'data-element-type=\"image')\n",
    "\n",
    "    with open(html_fn, 'w', encoding='utf-8') as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make flask file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_flask_app_py(page_dir_name):\n",
    "\n",
    "    app_template = \"\"\"from flask import Flask\n",
    "\n",
    "app = Flask(__name__, static_folder=\".\", static_url_path=\"/\")\n",
    "\"\"\"\n",
    "\n",
    "    for html_fn in glob(os.path.join(page_dir_name, \"*.html\")):\n",
    "        routing = re.search(fr\"(?<={page_dir_name}).*(?=\\.html)\", html_fn)[0]\n",
    "        function_name = re.sub(r'\\W+', '_', routing[1:])\n",
    "        \n",
    "        if \"home\" in routing:\n",
    "            routing = \"/\"\n",
    "        \n",
    "        route_template = f\"\"\"\n",
    "@app.route(\"{routing}\")\n",
    "def {function_name}():\n",
    "    return app.send_static_file(\"{html_fn.replace(\"./\", \"\")}\")\n",
    "\"\"\"\n",
    "\n",
    "        app_template += route_template\n",
    "\n",
    "    app_template += f\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=8000, host=\"0.0.0.0\")\n",
    "\"\"\"\n",
    "\n",
    "    return app_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "falsk_app_py = make_flask_app_py(page_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{page_dir_name.replace('./', '')}_app.py\", mode=\"w\") as f:\n",
    "    f.write(falsk_app_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kjg_ver39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
